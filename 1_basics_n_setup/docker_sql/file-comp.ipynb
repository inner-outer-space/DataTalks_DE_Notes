{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import warnings\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I noticed there was a difference in size of the parquet and csv files for the Green Jan 2019 Taxi data used in the 2023 cohort homework 1. So I wanted to check the other files that we are working with.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_files = {\n",
    "    \"2021_01_yellow\":\"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-01.parquet\",\n",
    "    \"2019_01_green\":\"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2019-01.parquet\",\n",
    "    \"2019_09_green\":\"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2019-09.parquet\"   \n",
    "    }\n",
    "csv_files = {\n",
    "    \"2021_01_yellow\":\"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2021-01.csv.gz\",\n",
    "    \"2019_01_green\":\"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-01.csv.gz\",\n",
    "    \"2019_09_green\":\"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-09.csv.gz\"   \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021_01_yellow (1369769, 19)\n",
      "2019_01_green (672105, 20)\n",
      "2019_09_green (449063, 20)\n",
      "2021_01_yellow (1369765, 18)\n",
      "2019_01_green (630918, 20)\n",
      "2019_09_green (449063, 20)\n"
     ]
    }
   ],
   "source": [
    "# Suppress warnings temporarily\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    for file_name, url in parquet_files.items():\n",
    "        r = requests.get(url)\n",
    "        df = pd.read_parquet(BytesIO(r.content))\n",
    "        print(file_name, df.shape)\n",
    "\n",
    "    for file_name, url in csv_files.items():\n",
    "        r = requests.get(url)\n",
    "        df = pd.read_csv(BytesIO(r.content), compression='gzip')\n",
    "        print(file_name, df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE TIME DOWNLOAD  \n",
    "#os.system(f'wget -O {parquet_name} {parquet_url}')\n",
    "#os.system(f'wget -O {csv_name} {csv_url}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de_zoom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
