{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from pyspark.sql import types \n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "|VendorID|lpep_pickup_datetime|lpep_dropoff_datetime|store_and_fwd_flag|RatecodeID|PULocationID|DOLocationID|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|ehail_fee|improvement_surcharge|total_amount|payment_type|trip_type|congestion_surcharge|\n",
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "|       2| 2020-01-12 18:15:04|  2020-01-12 18:19:52|                 N|         1|          41|          41|              1|         0.78|        5.5|  0.0|    0.5|      1.58|         0.0|     NULL|                  0.3|        7.88|           1|        1|                 0.0|\n",
      "|       2| 2020-01-31 20:24:10|  2020-01-31 20:31:51|                 N|         1|         173|          70|              1|         0.98|        7.0|  0.5|    0.5|       0.0|         0.0|     NULL|                  0.3|         8.3|           2|        1|                 0.0|\n",
      "|       2| 2020-01-07 08:16:53|  2020-01-07 08:41:39|                 N|         1|          74|         236|              1|          2.7|       16.0|  0.0|    0.5|      3.91|         0.0|     NULL|                  0.3|       23.46|           1|        1|                2.75|\n",
      "|       1| 2020-01-15 14:47:15|  2020-01-15 14:54:34|                 N|         1|          25|          66|              1|          0.8|        6.5|  0.0|    0.5|       0.0|         0.0|     NULL|                  0.3|         7.3|           2|        1|                 0.0|\n",
      "|    NULL| 2020-01-31 10:08:00|  2020-01-31 10:20:00|              NULL|      NULL|         259|          51|           NULL|         2.33|      22.49| 2.75|    0.0|       0.0|         0.0|     NULL|                  0.3|       25.54|        NULL|     NULL|                NULL|\n",
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_green = spark.read.parquet('data/pq/green/*/*')\n",
    "df_yellow = spark.read.parquet('data/pq/yellow/*/*')\n",
    "df_green.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lulu/spark/spark-3.5.0-bin-hadoop3/python/pyspark/sql/dataframe.py:329: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Register the DataFrames as a SQL temporary view\n",
    "df_green.registerTempTable('green')\n",
    "df_yellow.registerTempTable('yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_revenue = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    date_trunc('hour', lpep_pickup_datetime) AS hour, \n",
    "    PULocationID AS zone,\n",
    "\n",
    "    SUM(total_amount) AS amount,\n",
    "    COUNT(1) as number_records\n",
    "FROM\n",
    "    green\n",
    "WHERE \n",
    "    lpep_pickup_datetime >= '2020-01-01 00:00:00'\n",
    "GROUP BY\n",
    "    1, 2\n",
    "ORDER BY\n",
    "    1, 2 \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:==============>                                          (4 + 12) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+------------------+--------------+\n",
      "|               hour|zone|            amount|number_records|\n",
      "+-------------------+----+------------------+--------------+\n",
      "|2020-01-01 00:00:00|   7|            769.73|            45|\n",
      "|2020-01-01 00:00:00|  17|195.02999999999997|             9|\n",
      "|2020-01-01 00:00:00|  18|               7.8|             1|\n",
      "|2020-01-01 00:00:00|  22|              15.8|             1|\n",
      "|2020-01-01 00:00:00|  24|              87.6|             3|\n",
      "|2020-01-01 00:00:00|  25|             531.0|            26|\n",
      "|2020-01-01 00:00:00|  29|              61.3|             1|\n",
      "|2020-01-01 00:00:00|  32| 68.94999999999999|             2|\n",
      "|2020-01-01 00:00:00|  33|317.27000000000004|            11|\n",
      "|2020-01-01 00:00:00|  35|129.95999999999998|             5|\n",
      "|2020-01-01 00:00:00|  36|295.34000000000003|            11|\n",
      "|2020-01-01 00:00:00|  37|175.67000000000002|             6|\n",
      "|2020-01-01 00:00:00|  38| 98.78999999999999|             2|\n",
      "|2020-01-01 00:00:00|  40|            168.98|             8|\n",
      "|2020-01-01 00:00:00|  41|1363.9599999999991|            84|\n",
      "|2020-01-01 00:00:00|  42| 799.7599999999998|            52|\n",
      "|2020-01-01 00:00:00|  43|            107.52|             6|\n",
      "|2020-01-01 00:00:00|  47|              13.3|             1|\n",
      "|2020-01-01 00:00:00|  49|            266.76|            14|\n",
      "|2020-01-01 00:00:00|  51|              17.8|             2|\n",
      "+-------------------+----+------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_green_revenue.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/13 15:39:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "24/02/13 15:39:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/02/13 15:39:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/02/13 15:39:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/02/13 15:39:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/02/13 15:39:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "24/02/13 15:39:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "24/02/13 15:39:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "24/02/13 15:39:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 47.50% for 16 writers\n",
      "24/02/13 15:39:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "24/02/13 15:39:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "24/02/13 15:39:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "24/02/13 15:39:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/02/13 15:39:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/02/13 15:39:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/02/13 15:39:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/02/13 15:39:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n"
     ]
    }
   ],
   "source": [
    "df_green_revenue.repartition(20).write.parquet('data/report/revenue/green', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow_revenue = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    date_trunc('hour', tpep_pickup_datetime) AS hour, \n",
    "    PULocationID AS zone,\n",
    "\n",
    "    SUM(total_amount) AS amount,\n",
    "    COUNT(1) as number_records\n",
    "FROM\n",
    "    yellow\n",
    "WHERE \n",
    "    tpep_pickup_datetime >= '2020-01-01 00:00:00'\n",
    "GROUP BY\n",
    "    1, 2\n",
    "ORDER BY\n",
    "    1, 2 \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/13 15:40:01 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "24/02/13 15:40:01 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/02/13 15:40:01 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/02/13 15:40:01 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/02/13 15:40:01 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/02/13 15:40:01 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "24/02/13 15:40:01 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "24/02/13 15:40:01 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "24/02/13 15:40:01 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 47.50% for 16 writers\n",
      "24/02/13 15:40:01 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "24/02/13 15:40:01 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "24/02/13 15:40:01 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "24/02/13 15:40:01 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/02/13 15:40:01 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/02/13 15:40:01 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/02/13 15:40:01 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/02/13 15:40:01 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n"
     ]
    }
   ],
   "source": [
    "df_yellow_revenue.repartition(20).write.parquet('data/report/revenue/yellow', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOW JOIN THE TWO TABLES ON HOUR AND ZONE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_revenue_tmp = df_green_revenue \\\n",
    "    .withColumnRenamed('amount', 'green_amount') \\\n",
    "    .withColumnRenamed('number_records', 'green_number_records')\n",
    "    \n",
    "df_yellow_revenue_tmp = df_yellow_revenue \\\n",
    "    .withColumnRenamed('amount', 'yellow_amount') \\\n",
    "    .withColumnRenamed('number_records', 'yellow_number_records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df_green_revenue_tmp.join(df_yellow_revenue_tmp, on = ['hour', 'zone'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/13 15:48:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "24/02/13 15:48:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/02/13 15:48:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/02/13 15:48:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/02/13 15:48:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/02/13 15:48:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "24/02/13 15:48:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "24/02/13 15:48:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "24/02/13 15:48:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 47.50% for 16 writers\n",
      "24/02/13 15:48:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "24/02/13 15:48:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "24/02/13 15:48:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "24/02/13 15:48:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/02/13 15:48:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/02/13 15:48:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/02/13 15:48:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/02/13 15:48:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_join.write.parquet('data/report/revenue/join', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 62:==================================================>     (19 + 2) / 21]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+------------------+--------------------+------------------+---------------------+\n",
      "|               hour|zone|      green_amount|green_number_records|     yellow_amount|yellow_number_records|\n",
      "+-------------------+----+------------------+--------------------+------------------+---------------------+\n",
      "|2020-01-01 00:00:00|  55|129.29000000000002|                   4|              NULL|                 NULL|\n",
      "|2020-01-01 00:00:00|  60|            160.04|                   6|57.620000000000005|                    2|\n",
      "|2020-01-01 00:00:00|  61|            526.71|                  17|            146.64|                    3|\n",
      "|2020-01-01 00:00:00|  65|            199.49|                  10|            409.35|                   19|\n",
      "|2020-01-01 00:00:00|  71|              23.8|                   1|              NULL|                 NULL|\n",
      "|2020-01-01 00:00:00|  78|             34.46|                   2|              NULL|                 NULL|\n",
      "|2020-01-01 00:00:00|  88|              NULL|                NULL| 823.8000000000001|                   36|\n",
      "|2020-01-01 00:00:00| 106|             10.56|                   1|              NULL|                 NULL|\n",
      "|2020-01-01 00:00:00| 112|            312.26|                  18|119.47999999999999|                    8|\n",
      "|2020-01-01 00:00:00| 161|              NULL|                NULL| 9410.210000000001|                  488|\n",
      "|2020-01-01 00:00:00| 162|              NULL|                NULL| 4622.289999999997|                  268|\n",
      "|2020-01-01 00:00:00| 190|             61.97|                   4|              54.1|                    3|\n",
      "|2020-01-01 00:00:00| 255|            666.34|                  28|            537.66|                   27|\n",
      "|2020-01-01 01:00:00|   3|46.230000000000004|                   2|              NULL|                 NULL|\n",
      "|2020-01-01 01:00:00|  40|177.16000000000003|                   6|            313.54|                   15|\n",
      "|2020-01-01 01:00:00|  45|              NULL|                NULL|            898.44|                   49|\n",
      "|2020-01-01 01:00:00|  47|130.45999999999998|                   3|47.400000000000006|                    3|\n",
      "|2020-01-01 01:00:00|  77|             64.66|                   2|              NULL|                 NULL|\n",
      "|2020-01-01 01:00:00|  95|239.52000000000004|                  17|              94.0|                    6|\n",
      "|2020-01-01 01:00:00| 164|              NULL|                NULL| 9384.079999999998|                  488|\n",
      "+-------------------+----+------------------+--------------------+------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_join.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redo the Join based on rematerialized data from the original load \n",
    "rather than recreating it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_revenue = spark.read.parquet('data/report/revenue/green')\n",
    "df_yellow_revenue = spark.read.parquet('data/report/revenue/yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_revenue_tmp = df_green_revenue \\\n",
    "    .withColumnRenamed('amount', 'green_amount') \\\n",
    "    .withColumnRenamed('number_records', 'green_number_records')\n",
    "    \n",
    "df_yellow_revenue_tmp = df_yellow_revenue \\\n",
    "    .withColumnRenamed('amount', 'yellow_amount') \\\n",
    "    .withColumnRenamed('number_records', 'yellow_number_records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df_green_revenue_tmp.join(df_yellow_revenue_tmp, on = ['hour', 'zone'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+------------------+--------------------+------------------+---------------------+\n",
      "|               hour|zone|      green_amount|green_number_records|     yellow_amount|yellow_number_records|\n",
      "+-------------------+----+------------------+--------------------+------------------+---------------------+\n",
      "|2020-01-01 00:00:00|  55|129.29000000000002|                   4|              NULL|                 NULL|\n",
      "|2020-01-01 00:00:00|  60|            160.04|                   6|57.620000000000005|                    2|\n",
      "|2020-01-01 00:00:00|  61|            526.71|                  17|            146.64|                    3|\n",
      "|2020-01-01 00:00:00|  65|            199.49|                  10|            409.35|                   19|\n",
      "|2020-01-01 00:00:00|  71|              23.8|                   1|              NULL|                 NULL|\n",
      "|2020-01-01 00:00:00|  78|             34.46|                   2|              NULL|                 NULL|\n",
      "|2020-01-01 00:00:00|  88|              NULL|                NULL| 823.8000000000001|                   36|\n",
      "|2020-01-01 00:00:00| 106|             10.56|                   1|              NULL|                 NULL|\n",
      "|2020-01-01 00:00:00| 112|            312.26|                  18|119.47999999999999|                    8|\n",
      "|2020-01-01 00:00:00| 161|              NULL|                NULL| 9410.210000000001|                  488|\n",
      "|2020-01-01 00:00:00| 162|              NULL|                NULL| 4622.289999999997|                  268|\n",
      "|2020-01-01 00:00:00| 190|             61.97|                   4|              54.1|                    3|\n",
      "|2020-01-01 00:00:00| 255|            666.34|                  28|            537.66|                   27|\n",
      "|2020-01-01 01:00:00|   3|46.230000000000004|                   2|              NULL|                 NULL|\n",
      "|2020-01-01 01:00:00|  40|177.16000000000003|                   6|            313.54|                   15|\n",
      "|2020-01-01 01:00:00|  45|              NULL|                NULL|            898.44|                   49|\n",
      "|2020-01-01 01:00:00|  47|130.45999999999998|                   3|47.400000000000006|                    3|\n",
      "|2020-01-01 01:00:00|  77|             64.66|                   2|              NULL|                 NULL|\n",
      "|2020-01-01 01:00:00|  95|239.52000000000004|                  17|              94.0|                    6|\n",
      "|2020-01-01 01:00:00| 164|              NULL|                NULL| 9384.079999999998|                  488|\n",
      "+-------------------+----+------------------+--------------------+------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case where one table is big and the other is small\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = spark.read.parquet('data/report/revenue/join')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[hour: timestamp, zone: int, green_amount: double, green_number_records: bigint, yellow_amount: double, yellow_number_records: bigint]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read.parquet('zones/', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
      "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
      "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
      "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
      "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
      "|        16|       Queens|             Bayside|   Boro Zone|\n",
      "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
      "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
      "|        19|       Queens|           Bellerose|   Boro Zone|\n",
      "|        20|        Bronx|             Belmont|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zones.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_join.join(df_zones, df_join.zone == df_zones.LocationID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+--------------------+------------------+---------------------+---------+------------+\n",
      "|               hour|      green_amount|green_number_records|     yellow_amount|yellow_number_records|  Borough|service_zone|\n",
      "+-------------------+------------------+--------------------+------------------+---------------------+---------+------------+\n",
      "|2020-01-01 00:00:00|              NULL|                NULL|1214.8000000000002|                   56|Manhattan| Yellow Zone|\n",
      "|2020-01-01 00:00:00|              NULL|                NULL|10773.360000000004|                  455|Manhattan| Yellow Zone|\n",
      "|2020-01-01 00:00:00|143.77999999999997|                   4|             35.51|                    2| Brooklyn|   Boro Zone|\n",
      "|2020-01-01 00:00:00|            133.35|                   7|              NULL|                 NULL|   Queens|   Boro Zone|\n",
      "|2020-01-01 00:00:00|              NULL|                NULL| 4011.449999999998|                  188|Manhattan| Yellow Zone|\n",
      "|2020-01-01 00:00:00|             80.24|                   3|              NULL|                 NULL|    Bronx|   Boro Zone|\n",
      "|2020-01-01 00:00:00|              NULL|                NULL|              25.5|                    1|    Bronx|   Boro Zone|\n",
      "|2020-01-01 01:00:00|            598.15|                  18|464.51000000000005|                   18| Brooklyn|   Boro Zone|\n",
      "|2020-01-01 01:00:00|             86.43|                   3|              78.6|                    2|    Bronx|   Boro Zone|\n",
      "|2020-01-01 01:00:00|202.04999999999998|                   4|              NULL|                 NULL| Brooklyn|   Boro Zone|\n",
      "|2020-01-01 01:00:00|              NULL|                NULL| 9994.480000000005|                  583|Manhattan| Yellow Zone|\n",
      "|2020-01-01 01:00:00|              NULL|                NULL|              11.8|                    1|Manhattan|   Boro Zone|\n",
      "|2020-01-01 01:00:00|              NULL|                NULL| 5125.959999999997|                  291|Manhattan| Yellow Zone|\n",
      "|2020-01-01 01:00:00|              NULL|                NULL| 2970.329999999999|                  182|Manhattan| Yellow Zone|\n",
      "|2020-01-01 01:00:00|              NULL|                NULL| 8202.779999999995|                  412|Manhattan| Yellow Zone|\n",
      "|2020-01-01 01:00:00|              17.8|                   1|              19.8|                    1|Manhattan|   Boro Zone|\n",
      "|2020-01-01 01:00:00|33.900000000000006|                   3|             148.9|                    8|    Bronx|   Boro Zone|\n",
      "|2020-01-01 01:00:00|              NULL|                NULL|              43.0|                    1|    Bronx|   Boro Zone|\n",
      "|2020-01-01 01:00:00|             12.24|                   1|              NULL|                 NULL|    Bronx|   Boro Zone|\n",
      "|2020-01-01 01:00:00|             164.8|                   5|            138.22|                    3|   Queens|   Boro Zone|\n",
      "+-------------------+------------------+--------------------+------------------+---------------------+---------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_result = df_result.drop('LocationID','zone')\n",
    "df_result.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/13 16:45:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "24/02/13 16:45:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/02/13 16:45:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/02/13 16:45:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/02/13 16:45:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/02/13 16:45:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "24/02/13 16:45:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "24/02/13 16:45:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "24/02/13 16:45:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 47.50% for 16 writers\n",
      "24/02/13 16:45:20 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "24/02/13 16:45:20 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "24/02/13 16:45:20 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "24/02/13 16:45:20 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/02/13 16:45:20 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/02/13 16:45:20 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/02/13 16:45:20 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/02/13 16:45:20 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/02/13 16:45:20 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/02/13 16:45:20 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result.write.parquet('data/tmp/revenue-zones', mode='overwrite')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de_zoom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
