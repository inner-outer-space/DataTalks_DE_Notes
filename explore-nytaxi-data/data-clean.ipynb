{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os \n",
    "from datetime import datetime\n",
    "import mappings as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_name = 'data/yellow_taxi_jan_2021.parquet'\n",
    "csv_name = 'data/ny_taxi_location_lookup.csv'\n",
    "data_url=\"https://d37ci6vzurychx.cloutaxi_df_cleanront.net/trip-data/yellow_tripdata_2021-01.parquet\"\n",
    "lookup_url=\"https://d37ci6vzurychx.cloutaxi_df_cleanront.net/misc/taxi+_zone_lookup.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE TIME DOWNLOAD  \n",
    "# os.system(f'wget -O {parquet_name} {data_url}')\n",
    "# os.system(f'wget -O {csv_name} {lookup_url}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ IN DATA \n",
    "taxi_df_orig = pd.read_parquet(parquet_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK MEMORY USAGE \n",
    "memory_usage = taxi_df_orig.memory_usage(deep=True).sum() / (1024 ** 2)  # Convert to megabytes\n",
    "print(f\"Memory usage of DataFrame: {memory_usage:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAPPINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT MAPPING DICTIONARY\n",
    "mapping = mp.mapping_dict\n",
    "print(f'data type:{type(mapping)}', f'an example value: {mapping[\"payment_type\"][3]}')\n",
    "#dir(mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASIC INFO AND STATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df = taxi_df_orig.copy()\n",
    "taxi_df.columns = taxi_df.columns.str.lower()\n",
    "columns = taxi_df.columns\n",
    "columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REPLACE STORE AND FORWARD FLAG WITH A NUMERIC VALUE FOR ANALYSIS PURPOSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(taxi_df['store_and_fwd_flag'].unique())  \n",
    "# Replace \"Y\" with 1 and \"N\" with 2 \n",
    "taxi_df['store_and_fwd_flag'] = taxi_df['store_and_fwd_flag'].replace({\"Y\": 1, \"N\": 2}).astype(float) \n",
    "print(taxi_df['store_and_fwd_flag'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOOK AT NA, NULL, AND ZERO COUNTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_null_zero_datatypes(df):\n",
    "    have_values = [(df[col].notna() & (df[col] != 0)).sum() for col in df.columns]\n",
    "    nans = [df[col].isna().sum() for col in df.columns]\n",
    "    blanks = [(df[col] == ' ').sum() for col in df.columns]\n",
    "    zeros = [(df[col] == 0).sum() for col in df.columns]\n",
    "    data_types = [df[col].apply(lambda x: type(x)).unique() for col in df.columns]\n",
    "    len_data_types = [len(df[col].apply(lambda x: type(x)).unique()) for col in df.columns] \n",
    "    \n",
    "\n",
    "    df_clean_check = pd.DataFrame({\n",
    "        'Column Name': df.columns,\n",
    "        'have_values': have_values,\n",
    "        '# NAs': nans,\n",
    "        '# Blanks': blanks,\n",
    "        '# Zeros': zeros,\n",
    "        '# Data Types': len_data_types,\n",
    "        'Data Types': data_types\n",
    "    })\n",
    "\n",
    "    return df_clean_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df_info = nan_null_zero_datatypes(taxi_df)\n",
    "taxi_df_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASIC STATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UNDERSTANDING THE DISCRETE VALUE COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRINT UNIQUE VALUES FOR COLUMNS WITH DISCRETE VALUES\n",
    "print(\"Value counts for columns with discrete values:\")\n",
    "for col in taxi_df.columns:\n",
    "    unique_values = taxi_df[col].unique()\n",
    "    if len(unique_values) < 20:\n",
    "        print(f\"{col}:\")\n",
    "        for value in unique_values:\n",
    "            count = (taxi_df[col] == value).sum()\n",
    "            print(f\"    {value}: {count}\")\n",
    "            \n",
    "        # OR FOLLOWING THE FIRST PRINT\n",
    "        #value_counts = taxi_df[col].value_counts()\n",
    "        #for value, count in value_counts.items():\n",
    "        #    print(f\"    {value}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADD NEW COLUMNS \n",
    "Adding now because duration will be used to select some records for removal. \n",
    "\n",
    "- duration_minute\n",
    "- holiday flag \n",
    "- math check --> Total Amount - Fare and all Fees/ Charges\n",
    "\n",
    "EVENTUALLY WANT TO ADD \n",
    "- Weather - temp and percipitation (rain/snow) flag\n",
    "- Daytime - flag Y if between sunrise and sunset for that day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BREAK OUT DROP OFF DATE INTO SEPARATE COLUMNS\n",
    "taxi_df['drop_off_day'] = taxi_df['tpep_dropoff_datetime'].dt.day\n",
    "taxi_df['drop_off_hour'] = taxi_df['tpep_dropoff_datetime'].dt.hour\n",
    "taxi_df['drop_off_dow'] = taxi_df['tpep_dropoff_datetime'].dt.dayofweek\n",
    "\n",
    "# ADD PICK UP DATE INTO SEPARATE COLUMNS\n",
    "taxi_df['pick_up_day'] = taxi_df['tpep_pickup_datetime'].dt.day\n",
    "taxi_df['pick_up_hour'] = taxi_df['tpep_pickup_datetime'].dt.hour\n",
    "taxi_df['pick_up_dow'] = taxi_df['tpep_pickup_datetime'].dt.dayofweek\n",
    "\n",
    "# ADD DURATION IN MINUTES COLUMN\n",
    "taxi_df['duration_minute'] = (\n",
    "    (taxi_df['tpep_dropoff_datetime'] - taxi_df['tpep_pickup_datetime'])\n",
    "    .apply(lambda x: round(x.total_seconds() / 60))\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "taxi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD HOLIDAY FLAG COLUMN\n",
    "\n",
    "# List of US holidays in Jan 2021 \n",
    "holidays = ['2021-01-01', '2021-01-18'] \n",
    "\n",
    "# Add a holiday flag column\n",
    "taxi_df['is_holiday'] = (\n",
    "    taxi_df['tpep_dropoff_datetime']\n",
    "    .apply(lambda x: x.strftime('%Y-%m-%d') in holidays)\n",
    ")\n",
    "\n",
    "# Look at records with holidays\n",
    "holiday = taxi_df[taxi_df['is_holiday'] == True]\n",
    "print(f\"Records with holidays: {holiday.shape[0]}\")\n",
    "holiday.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK IF THE AMOUNTS ADD UP\n",
    "\n",
    "money_cols = ['payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'congestion_surcharge', 'total_amount', 'math_check']\n",
    "\n",
    "taxi_df['math_check'] = (\n",
    "    taxi_df['total_amount'] -\n",
    "    taxi_df['extra'] -\n",
    "    taxi_df['mta_tax'] -\n",
    "    taxi_df['tip_amount'] -\n",
    "    taxi_df['tolls_amount'] -\n",
    "    taxi_df['improvement_surcharge'] -\n",
    "    taxi_df['congestion_surcharge'] -\n",
    "    taxi_df['fare_amount']\n",
    ").round(2)\n",
    "\n",
    "\n",
    "math_check_df = taxi_df[taxi_df['math_check'] != 0]\n",
    "print(math_check_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTIONABLE DATA \n",
    "### Look into these further\n",
    "\n",
    "- **airport_fee** -- only 5 records with 0 and rest nan --> drop this columns\n",
    "- **negatives** \n",
    "- **NaNs** -- - 98352 records with NA in passenger_count, rate_code_id, store_and_fwd_flag, and congestion_surcharge and 0 in Payment type<br> --> account for **.07%** of the records\n",
    "- **trip distance** -- 19952 records with trip_distance = 0 \n",
    "- **vendor_id** -- 10291 records with vendor_id = 6\n",
    "- **passengers** -- 26726 records with 0 passengers\n",
    "- **ratecodeid** -- 36 records with ratecodeid = 99 \n",
    "- **total amount** 452 records with 0 total amount\n",
    "- negative amounts - check to see if all negative taxes correspond to negative amounts -- guessing they are refunds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DROP AIRPORT FEE COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP THE AIRPORT FEE COLUMN\n",
    "taxi_df = taxi_df.drop('airport_fee', axis=1)\n",
    "taxi_df.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEGATIVE AMOUNTS\n",
    "First suspected that these were refunds but the records have non negative trip distances. \n",
    "The rows with neg fare amount will be dropped. That captures all but few rows with other neg values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOOK AT COUNTS OF NEGATIVE VALUES\n",
    "print('COUNTS OF NEGATIVE VALUES PER COLUMN')\n",
    "for col in taxi_df.columns:\n",
    "    if taxi_df[col].dtype != 'datetime64[us]':\n",
    "        negatives = (taxi_df[col] < 0).sum()\n",
    "        if negatives > 0: \n",
    "            print(f\"    {col}: {negatives}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIRM THAT ALMOST ALL OF THE NEGATIVE TAXES, CHARGES ETC OCCUR WITH THE NEGATIVE FARES\n",
    "neg_fare = taxi_df[taxi_df['fare_amount'] < 0]\n",
    "for col in neg_fare.columns:\n",
    "    if neg_fare[col].dtype != 'datetime64[us]':\n",
    "        negatives = (neg_fare[col] < 0).sum()\n",
    "        if negatives > 0: \n",
    "            print(f\"    {col}: {negatives}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STATS FOR NEGATIVE FARES DATAFRAME\n",
    "neg_fare.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_neg_fare = neg_fare.isna().sum()\n",
    "print(nan_neg_fare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECK NaN RECORDS \n",
    "All NaNs are in the same rows. These rows will be dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK IF ALL NaNs ARE IN THE SAME ROWS\n",
    "na_check = taxi_df[taxi_df['passenger_count'].isna()]\n",
    "print(f\"Rows with NAs: {na_check.shape[0]} \")\n",
    "na_check.describe().round(2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_check[na_check['trip_distance'] == 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RECORDS WITH TRIP DISTANCE = 0 \n",
    "These records will be kept but will be excluded from any distance stats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECORDS WITH 0 TRIP DISTANCE\n",
    "zero_distance = taxi_df[taxi_df['trip_distance'] == 0]\n",
    "print(f\"Records with 0 trip distance: {zero_distance.shape[0]} \")\n",
    "zero_distance.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RECORDS WITH INVALID VENDOR ID (6) \n",
    "These all occur with the NaN combo. They will be dropped with the NaN drop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECORDS WITH VENDOR ID = 6\n",
    "vendor_6 = taxi_df[taxi_df['vendorid'] == 6]\n",
    "print(f\"Records with vendor id = 6: {vendor_6.shape[0]} \")\n",
    "vendor_6.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RECORDS WITH NO PASSENGERS\n",
    "This could be a data entry error. These records will be kept but excluded from per passenger stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECORDS WITH 0 PASSANGERS\n",
    "zero_passangers = taxi_df[taxi_df['passenger_count'] == 0]\n",
    "print(f\"Records with 0 passengers: {zero_passangers.shape[0]} \")\n",
    "zero_passangers.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONlY 5 RECORDS WITH 0 PASSENGERS AND ZERO FARE\n",
    "zero_passangers[zero_passangers['total_amount'] == 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RECORDS WITH INVALID RATECODEID \n",
    "There are only 36 records. These will be deleted since there are not that many and it will make analysis easier later. \n",
    "Could try and figure out how the rate code is determined and see if the cost per time or distance matches the other rate codes... but that is too much work for 36 records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECORDS WITH RATECODEID = 99\n",
    "ratecodeid_99 = taxi_df[taxi_df['ratecodeid'] == 99]\n",
    "print(f\"Records with ratecodeid = 99: {ratecodeid_99.shape[0]} \")\n",
    "ratecodeid_99.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONlY 6 RECORDS WITH INVALID RATECODEID AND ZERO FARE\n",
    "ratecodeid_99[ratecodeid_99['total_amount'] == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_ratecodeid_99 = ratecodeid_99.isna().sum()\n",
    "print(nan_ratecodeid_99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECK DATES AND EXCLUDE RECORDS WITH DROP OF DATE OUTSIDE OF JANUARY\n",
    "Since the rate code is selected at drop off, I am assuming that the fare is also associated with the drop off. Records will be kept as long as the drop off time is in the month of Jan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK IF RECORDS OUTSIDE OF JAN 2021 - BASED ON DROP OFF ONLY \n",
    "min_date = datetime(2021, 1, 1)\n",
    "max_date = datetime(2021, 2, 1)\n",
    "# Filter for dates less than the certain date\n",
    "filtered_do_taxi_df = taxi_df[(taxi_df['tpep_dropoff_datetime'] < min_date) | (taxi_df['tpep_dropoff_datetime'] >= max_date)]\n",
    "print(f\"Records outside of Jan 2021: {filtered_do_taxi_df.shape[0]} \")\n",
    "filtered_do_taxi_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_filtered_do_taxi_df = filtered_do_taxi_df[filtered_do_taxi_df.isna().any(axis=1)]\n",
    "nan_filtered_do_taxi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_filtered_do_taxi_df = filtered_do_taxi_df.isna().sum()\n",
    "print(nan_filtered_do_taxi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK IF THESE INCLUDE NEGATIVE VALUES\n",
    "for col in filtered_do_taxi_df.columns:\n",
    "    if filtered_do_taxi_df[col].dtype != 'datetime64[us]':\n",
    "        negatives = (filtered_do_taxi_df[col] < 0).sum()\n",
    "        if negatives > 0: \n",
    "            print(f\"    {col}: {negatives}\")\n",
    "        else:\n",
    "            print(f\"    {col}: no negatives\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK IF RECORDS OUTSIDE OF JAN 2021 - BASED ON PICK UP AND DROP OFF \n",
    "min_date = datetime(2021, 1, 1)\n",
    "max_date = datetime(2021, 2, 1)\n",
    "# Filter for dates less than the certain date\n",
    "filtered_dopu_taxi_df_clean = taxi_df[((taxi_df['tpep_pickup_datetime'] < min_date) & (taxi_df['tpep_dropoff_datetime'] < min_date)) \n",
    "                      | ((taxi_df['tpep_pickup_datetime'] > max_date) & (taxi_df['tpep_dropoff_datetime'] > max_date))]\n",
    "print(f\"Records outside of Jan 2021: {filtered_dopu_taxi_df_clean.shape[0]} \")\n",
    "filtered_dopu_taxi_df_clean.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DROP ROWS BASED ON ABOVE\n",
    "1. With negative fare amount - 6769 records 114 of which fall into another bucket (NaN) \n",
    "2. With invalid ratecodeid - 36 \n",
    "3. With NaNs - 98352 records \n",
    "4. With drop off time not in Jan 2021 - 137 records 4 of which fall into another bucket (NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPECTED ROWS TO DROP\n",
    "print(f'Expected dropped rows: {6769 - 114 + 36 + 98352 + 137 - 4}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df_clean = (\n",
    "    taxi_df[taxi_df['fare_amount'] >= 0]\n",
    "    .query('ratecodeid != 99')\n",
    "    .query('@min_date <= tpep_dropoff_datetime < @max_date')\n",
    "    .dropna()\n",
    ")\n",
    "print(f'Dropped Rows: {1369769 - taxi_df_clean.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OUTLIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df_clean.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERY LONG TRIP DISTANCE \n",
    "print(taxi_df_clean.shape[0])\n",
    "taxi_df_clean.drop(taxi_df_clean[taxi_df_clean['trip_distance'] >= 500].index, inplace = True)\n",
    "print(taxi_df_clean.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNBELIEVABLE FARE AMOUNTS \n",
    "# The records with trip distance 0 or 2 miles and high fare amounts are likely to be errors or money laundering. \n",
    "print(taxi_df_clean[(taxi_df_clean['fare_amount'] >= 300) & (taxi_df_clean['trip_distance'] <= 10)].shape[0])\n",
    "taxi_df_clean[(taxi_df_clean['fare_amount'] >= 300) & (taxi_df_clean['trip_distance'] <= 10)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERY HIGH FARE AMOUNTS AS IT SKEWS THE DATA - THESE OUTLIERS CAN BE LOOKED AT INDIVIDUALLY\n",
    "print(taxi_df_clean[taxi_df_clean['total_amount'] >= 500].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOOK AT RECORDS WITH FARE AMOUNT GREATER THAN $300, 0 DISTANCE, AND DURATION LESS THAN 2 MINUTES \n",
    "# These are likely errors or money laundering  -  1297 records\n",
    "zero_distance2 = (\n",
    "    taxi_df_clean[(taxi_df_clean['trip_distance'] == 0) \n",
    "    & (taxi_df_clean['duration_minute'] < 2)\n",
    "    & (taxi_df_clean['total_amount'] > 50)]\n",
    ")\n",
    "print(zero_distance2.shape[0])  \n",
    "zero_distance2.sort_values(by=['total_amount'], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP THE RECORDS WITH FARE AMOUNT GREATER THAN $300, 0 DISTANCE, AND DURATION LESS THAN 2 MINUTES\n",
    "taxi_df_clean = taxi_df_clean[~((taxi_df_clean['trip_distance'] == 0) & (taxi_df_clean['duration_minute'] < 2) & (taxi_df_clean['total_amount'] > 50))]\n",
    "taxi_df_clean.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP THE RECORDS WITH TOTAL FARE AMOUNT GREATER THAN $500\n",
    "taxi_df_clean = taxi_df_clean[~(taxi_df_clean['total_amount'] > 500)]\n",
    "taxi_df_clean.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LONG DURATION TRIPS  - THE DRIVER LIKELY FORGOT TO TURN OFF THE METER\n",
    "# LEAVE THEM IN THE DATASET BUT EXCLUDE FROM DURATION ANALYSIS\n",
    "print(taxi_df_clean[(taxi_df_clean['duration_minute'] >= 500) & (taxi_df_clean['trip_distance'] < 200)].shape[0])\n",
    "print(taxi_df_clean[(taxi_df_clean['duration_minute'] >= 1000)].shape[0])\n",
    "taxi_df_clean[taxi_df_clean['duration_minute'] >= 1000].sort_values(by=['trip_distance'], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NO CHARGE (payment_type = 3) and DISPUTE TRIPS (payment_type = 4)\n",
    "Review some records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_charge = taxi_df_clean[taxi_df_clean['payment_type'] == 3]   \n",
    "print(f'No charge records: {no_charge.shape[0]}')\n",
    "no_charge.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispute = taxi_df_clean[taxi_df_clean['payment_type'] == 4]   \n",
    "print(f'Dispute records: {dispute.shape[0]}')\n",
    "dispute.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPORT CLEANED DATA TO FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df_clean.to_parquet('data/yellow_taxi_jan_2021_clean.parquet')\n",
    "taxi_df_clean.to_pickle(\"data/yellow_taxi_jan_2021_clean.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['passenger_count', 'vendorid', 'ratecodeid', 'store_and_fwd_flag','payment_type', 'pulocationid', 'dolocationid','drop_off_day', 'drop_off_hour','drop_off_dow', 'pick_up_day', 'pick_up_hour', 'pick_up_dow','is_holiday']\n",
    "print(len(categorical_cols))\n",
    "\n",
    "numeric_cols = ['trip_distance', 'duration_minute', 'total_amount', 'fare_amount', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'mta_tax', 'extra', 'congestion_surcharge', 'math_check']\n",
    "print(len(numeric_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 3, figsize=(12, 8))\n",
    "\n",
    "for i, column in enumerate(numeric_cols):\n",
    "    taxi_var = taxi_df_clean[column]\n",
    "    mean = taxi_var.mean()\n",
    "    std_dev = taxi_var.std()\n",
    "    \n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "    \n",
    "    sns.histplot(taxi_var, bins=3000, ax=axs[row, col])\n",
    "    axs[row, col].set_title(column.capitalize())\n",
    "    \n",
    "    # Set x-axis limits based on min and max values in the column\n",
    "    axs[row, col].set_xlim(mean - 3*std_dev, mean + 3*std_dev)\n",
    "    \n",
    "    axs[row, col].axvline(taxi_var.mean(), color='red', label='Mean')\n",
    "    axs[row, col].axvline(taxi_var.mean() - taxi_var.std(), color='green', linestyle='--', label='Std Dev')\n",
    "    axs[row, col].axvline(taxi_var.mean() + taxi_var.std(), color='green', linestyle='--')\n",
    "\n",
    "# Add a single legend for all four plots\n",
    "handles, labels = axs[0, 0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, bbox_to_anchor=(1, 1), loc='right', ncol=1)\n",
    "\n",
    "# Add a title for the whole figure\n",
    "fig.suptitle('Taxi Metrics Histograms', fontsize=16, y=1.05)\n",
    "\n",
    "# Add some padding between the subplots\n",
    "plt.subplots_adjust(hspace=1)\n",
    "\n",
    "# display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='drop_off_day', y='fare_amount', data=taxi_df_clean, hue='drop_off_dow', palette='rainbow', showfliers=False, legend=False)\n",
    "plt.xlabel('Drop-off Day of Month')\n",
    "plt.ylabel('Total Amount')\n",
    "plt.title('Boxplot of Total Amount by Drop-off Day of Week')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x='drop_off_dow', y='fare_amount', data=taxi_df, hue='drop_off_dow', palette='rainbow', legend=False)\n",
    "plt.xlabel('Drop-off Day of Week')\n",
    "plt.ylabel('Total Amount')\n",
    "plt.title('Boxplot of Total Amount by Drop-off Day of Week')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de_zoom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
